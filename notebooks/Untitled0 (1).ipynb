{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNCTs5JvapOy1zgqVavn+Ny"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","import random\n","from tqdm import tqdm\n","from pathlib import Path\n","from concurrent.futures import ThreadPoolExecutor\n","\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.metrics import make_scorer, mean_squared_error, mean_gamma_deviance\n","from sklearn.metrics import cohen_kappa_score\n","from sklearn.model_selection import StratifiedKFold, KFold\n","from sklearn.model_selection import cross_val_score\n","from sklearn.model_selection import cross_val_predict\n","from sklearn.preprocessing import OrdinalEncoder\n","from sklearn.ensemble import VotingRegressor\n","from sklearn.impute import SimpleImputer, KNNImputer\n","\n","from scipy.optimize import minimize\n","import optuna\n","\n","import optuna.integration.lightgbm as lgb\n","\n","#from sklearn.ensemble import RandomForestRegressor\n","#from sklearn.experimental import enable_iterative_imputer\n","#from sklearn.impute import IterativeImputer\n","\n","import warnings\n","warnings.filterwarnings('ignore')\n","\n","\n","SEED = 42"],"metadata":{"id":"RJ6W4HhQPBOo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["root = Path('/content')\n","df_train = pd.read_csv(root / 'sample_loss_data_shape.csv', parse_dates=[\"yyyymm\"])\n","#df_test = pd.read_csv(root / 'test.csv')"],"metadata":{"id":"oiTxljkpY9Z6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train['diff'] = df_train['input_qty'] - df_train['output_qty']\n","df_train[\"month\"] = pd.to_datetime(df_train[\"yyyymm\"]).dt.to_period(\"M\")\n","df_train.head()"],"metadata":{"id":"nRjI-9ifdmnb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["feature_cols = ['product_id', 'process_id', 'input_qty', 'shape_mm']\n","target_col = 'diff'"],"metadata":{"id":"mkqiWjDTZId6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train = df_train.dropna(subset=[target_col])\n","df_train[target_col].isnull().any()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yHpGr-6CZSs4","executionInfo":{"status":"ok","timestamp":1748158523736,"user_tz":-540,"elapsed":24,"user":{"displayName":"あいうえお","userId":"04506529592308542310"}},"outputId":"29daa465-7c00-483a-c48f-218b5612d476"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["np.False_"]},"metadata":{},"execution_count":117}]},{"cell_type":"code","source":["# 初期訓練期間\n","start_test = df_train[\"month\"].min() + 12  # 12 ヶ月後から予測開始\n","months = df_train[\"month\"].unique()\n","results = []\n","\n","train_idx = df_train[\"month\"] < start_test"],"metadata":{"id":"JJx6LHt8f9Ea"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train_hy = df_train[train_idx]\n","df_train_hy[\"diff\"] = df_train_hy[\"diff\"].astype(\"float64\")\n","df_train_hy.tail()"],"metadata":{"id":"BKTzf2PNhInv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gamma_scorer = make_scorer(mean_gamma_deviance)\n","rmse_scorer2 = make_scorer(mean_squared_error, squared=False)\n","rmse_scorer = make_scorer(mean_squared_error)"],"metadata":{"id":"AJt0MzhBPGba"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zjGq6nS9N_0p"},"outputs":[],"source":["class CustomLGBMRegressor2(lgb.LGBMRegressor):\n","    def __init__(self, random_state, **kwargs):\n","        if 'random_state' in kwargs:\n","            random_state = kwargs.pop('random_state')\n","        super().__init__(random_state=random_state, **kwargs)\n","        self.enc_prod = OrdinalEncoder(\n","                          #categories=categories,\n","                          dtype=np.int32,\n","                          handle_unknown='use_encoded_value',\n","                          unknown_value=-1,\n","                          encoded_missing_value=-2,\n","                          min_frequency=2)\n","        self.enc_proc = OrdinalEncoder(\n","                          #categories=categories,\n","                          dtype=np.int32,\n","                          handle_unknown='use_encoded_value',\n","                          unknown_value=-1,\n","                          encoded_missing_value=-2,\n","                          min_frequency=2)\n","\n","        #self.imputer = IterativeImputer(RandomForestRegressor())\n","\n","\n","#    def _encode(self, X, fit=False):\n","#        X = X.copy()\n","#        for col in ['product_id', 'process_id']:\n","#            X[col] = X[col].astype('category')\n","#        return X\n","\n","    def _encode(self, X, fit=False):\n","        X = X.copy()\n","        if fit:\n","            X['product_id'] = self.enc_prod.fit_transform(X[['product_id']]).ravel()\n","            X['process_id'] = self.enc_proc.fit_transform(X[['process_id']]).ravel()\n","        else:\n","            X['product_id'] = self.enc_prod.transform(X[['product_id']]).ravel()\n","            X['process_id'] = self.enc_proc.transform(X[['process_id']]).ravel()\n","        return X\n","\n","    def fit(self, X, y, **kwargs):\n","        X_enc = self._encode(X, fit=True)\n","        super().fit(X_enc, y, **kwargs)\n","\n","\n","#        super().fit(X, y, **kwargs)\n","        y_pred = super().predict(X_enc, **kwargs)\n","        #return self\n","#        X_enc = self._encode(X, fit=True)\n","#        super().fit(X, y, categorical_feature=['product_id','process_id'], **kwargs)\n","        #print(f'X:{X_enc.head()}')\n","        #print(f'y:{y}')\n","        #print(f'y_pred-y:{y_pred-y}')\n","        #print(self.random_state)\n","        return self\n","\n","    def predict(self, X, **kwargs):\n","        X_enc = self._encode(X, fit=False)\n","        y_pred = super().predict(X_enc, **kwargs)\n","        return y_pred"]},{"cell_type":"code","source":["#Nested CV\n","# ---------------- データ ---------------------\n","X = df_train_hy[feature_cols]\n","y = df_train_hy[target_col]\n","\n","outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n","outer_scores = []\n","best_params_each_fold = []\n","\n","for outer_i, (train_idx, test_idx) in enumerate(outer_cv.split(X, y), 1):\n","    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n","    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n","\n","    inner_cv = KFold(n_splits=3, shuffle=True, random_state=outer_i)\n","\n","    # -------- Optuna objective ---------------\n","    def lgb_objective(trial):\n","      params = {\n","          'objective':         'gamma',\n","          'verbosity':         -1,\n","           #'n_iter':            200,\n","          'random_state':      SEED,\n","          'boosting_type':     'gbdt',\n","          #\"lambda_l1\":        trial.suggest_float(\"lambda_l1\", 1e-3, 0.01, log=True),\n","          #'lambda_l2':         trial.suggest_float('lambda_l2', 1e-3, 0.01, log=True),\n","          'learning_rate':     trial.suggest_float('learning_rate', 1e-2, 1e-1, log=True),\n","          #'max_depth':         trial.suggest_int('max_depth', 2, 2),\n","          #'num_leaves':        trial.suggest_int('num_leaves', 2, 2),\n","          #'colsample_bytree':  trial.suggest_float('colsample_bytree', 0.4, 1.0),\n","          #'colsample_bynode':  trial.suggest_float('colsample_bynode', 0.4, 1.0),\n","          #'bagging_fraction':  trial.suggest_float('bagging_fraction', 0.4, 1.0),\n","          #'bagging_freq':      trial.suggest_int('bagging_freq', 1, 2),\n","          'min_data_in_leaf':  trial.suggest_int('min_data_in_leaf', 1, 2),\n","      }\n","\n","      cv = KFold(3, shuffle=True, random_state=SEED)\n","      estimator = CustomLGBMRegressor2(randome_state=SEED, **params)\n","      #print(f'X:{X.head()}')\n","      #print(f'y:{y}')\n","\n","      val_scores = cross_val_score(\n","            estimator=estimator,\n","            X=X_train, y=y_train,\n","            cv=inner_cv,\n","            scoring=gamma_scorer,\n","        )\n","\n","\n","      return np.mean(val_scores)\n","\n","    study = optuna.create_study(direction='minimize', study_name='Regressor')\n","    study.optimize(lgb_objective, n_trials=10, show_progress_bar=True)\n","\n","    best_params = study.best_trial.params\n","    best_params_each_fold.append(best_params)\n","\n","    # -------- Outer-test 評価 ----------------\n","    final_model = CustomLGBMRegressor2(random_state=SEED, **best_params)\n","\n","    # early-stopping を効かせる\n","    final_model.fit(\n","        X_train, y_train,\n","        #eval_set=[(X_test, y_test)],\n","        #early_stopping_rounds=50,\n","        #verbose=False\n","    )\n","\n","    y_pred = final_model.predict(X_test)\n","    gamma = mean_gamma_deviance(y_test, y_pred)\n","    outer_scores.append(gamma)\n","    print(f\"Fold {outer_i} gamma = {gamma:.4f}\")\n","\n","# ------------- まとめ ------------------------\n","print(\"\\n=== Nested CV result ===\")\n","print(f\"Mean gamma : {np.mean(outer_scores):.4f} ± {np.std(outer_scores):.4f}\")\n","\n","pd.set_option(\"display.max_columns\", None)\n","print(pd.DataFrame(best_params_each_fold))"],"metadata":{"id":"Hb5oWbV-9u2T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def lgb_objective(trial):\n","    params = {\n","        'objective':         'gamma',\n","        'verbosity':         -1,\n","        #'n_iter':            200,\n","        'random_state':      SEED,\n","        'boosting_type':     'gbdt',\n","        #\"lambda_l1\":        trial.suggest_float(\"lambda_l1\", 1e-3, 0.01, log=True),\n","        #'lambda_l2':         trial.suggest_float('lambda_l2', 1e-3, 0.01, log=True),\n","        'learning_rate':     trial.suggest_float('learning_rate', 1e-2, 1e-1, log=True),\n","        #'max_depth':         trial.suggest_int('max_depth', 2, 2),\n","        #'num_leaves':        trial.suggest_int('num_leaves', 2, 2),\n","        #'colsample_bytree':  trial.suggest_float('colsample_bytree', 0.4, 1.0),\n","        #'colsample_bynode':  trial.suggest_float('colsample_bynode', 0.4, 1.0),\n","        #'bagging_fraction':  trial.suggest_float('bagging_fraction', 0.4, 1.0),\n","        #'bagging_freq':      trial.suggest_int('bagging_freq', 1, 2),\n","        'min_data_in_leaf':  trial.suggest_int('min_data_in_leaf', 1, 2),\n","    }\n","\n","    X = df_train_hy[feature_cols]\n","    y = df_train_hy[target_col]\n","    #cv = StratifiedKFold(5, shuffle=True, random_state=SEED)\n","    cv = KFold(3, shuffle=True, random_state=SEED)\n","    estimator = CustomLGBMRegressor2(**params)\n","    #print(f'X:{X.head()}')\n","    #print(f'y:{y}')\n","\n","    val_scores = cross_val_score(\n","        estimator=estimator,\n","        X=X, y=y,\n","        cv=cv,\n","        scoring=gamma_scorer,\n","    )\n","\n","    return np.mean(val_scores)"],"metadata":{"id":"K33eD1LtJo-q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["params = study.best_params\n","\n","model = CustomLGBMRegressor2(**params, random_state=SEED)\n"],"metadata":{"id":"BUn82-OLJuJ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import shap"],"metadata":{"id":"AjNbT4rxO9ej"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# 初期訓練期間\n","start_test = df_train[\"month\"].min() + 12  # 12 ヶ月後から予測開始\n","months = df_train[\"month\"].unique()\n","results = []\n","\n","train_idx = df_train[\"month\"] < start_test\n","\n","# SHAP値を格納するための新しいカラムを初期化\n","# 各特徴量に対応するSHAP値の新しいカラムを作成\n","for col in feature_cols:\n","    df_train[f'shap_{col}'] = np.nan\n","\n","for m in tqdm(months[months >= start_test]):\n","    # --- 学習データ / 予測データ ---\n","    X_train, y_train = df_train.loc[train_idx, feature_cols], df_train.loc[train_idx, target_col]\n","    X_pred  = df_train.loc[df_train[\"month\"] == m, feature_cols]\n","    y_true  = df_train.loc[df_train[\"month\"] == m, target_col]\n","    #w_pred  = df_train.loc[df_train[\"month\"] == m, \"inp\"]          # 重み用\n","\n","    # --- モデル再学習（必要なら 3 ヶ月ごと check） ---\n","    model.fit(X_train, y_train)\n","\n","    # --- 予測 & 残差 ---\n","    y_hat = model.predict(X_pred)\n","    df_train.loc[df_train[\"month\"] == m, \"y_hat\"] = y_hat\n","    df_train.loc[df_train[\"month\"] == m, \"residual\"] = y_true - y_hat\n","\n","    # --- KPI 集計（工程 A を例） ---\n","    #mask_kpi = (df[\"month\"] == m) & (df[\"process_id\"] == \"A\")\n","    #kpi_exp  = (df.loc[mask_kpi, \"y_hat\"] * w_pred[mask_kpi]).sum() / w_pred[mask_kpi].sum()\n","    #kpi_act  = (df.loc[mask_kpi, \"loss_rate\"] * w_pred[mask_kpi]).sum() / w_pred[mask_kpi].sum()\n","    #delta_kpi = kpi_act - kpi_exp\n","\n","    # --- Δ分解 ---\n","    #sub = df.loc[mask_kpi].copy()\n","    #sub[\"delta_qty\"] = (sub[\"loss_rate\"] - sub[\"y_hat\"]) * sub[\"inp\"]\n","    #contrib = (sub.groupby(\"product_id\")[\"delta_qty\"].sum()\n","    #             .sort_values(key=abs, ascending=False).head(10))\n","\n","    # --- SHAP（任意） ---\n","    X_enc = model._encode(X_pred, fit=False)\n","    expl = shap.TreeExplainer(model)\n","    shap_vals = expl.shap_values(X_enc, check_additivity=False)\n","    #df_train.loc[df_train[\"month\"] == m, \"shap\"] = shap_vals\n","    for i, col in enumerate(feature_cols):\n","        df_train.loc[df_train[\"month\"] == m, f'shap_{col}'] = shap_vals[:, i]\n","    #shap_df   = pd.DataFrame(shap_vals, columns=X_pred.columns).mul(w_pred.values, axis=0)\n","    #shap_prod = shap_df.filter(like=\"product_\").sum().sort_values(key=abs, ascending=False).head(10)\n","\n","    #results.append({\n","    #    \"month\": m, \"kpi_exp\": kpi_exp, \"kpi_act\": kpi_act,\n","    #    \"delta\": delta_kpi, \"top_delta\": contrib, \"top_shap\": shap_prod\n","    #})\n","\n","    # --- 訓練セットに当月を追加して次ループへ ---\n","    train_idx |= (df_train[\"month\"] == m)"],"metadata":{"id":"ccGCUw1EKoFp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_train.to_csv(os.path.join(root, 'sample_loss_data_result.csv'), encoding='utf-8')"],"metadata":{"id":"iyi6wdmtR6zz"},"execution_count":null,"outputs":[]}]}